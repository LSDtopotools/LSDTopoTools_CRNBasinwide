= Tools for calculating basinwide denudation rates from cosmogenic nuclides

The repository contains the code for calculating denudation rates based
on ^10^Be and ^26^Al concentrations measured in stream sediments.

It is the software behind the CAIRN method, as described in Mudd et al., 2016 ESURFD. 

This code is part of the http://lsdtopotools.github.io/[LSDTopoTools software package].

The versions here are updated on a semi regular basis. 

For instructions, go to the http://lsdtopotools.github.io/LSDTT_book/[LSDTopoTools documentation website].

Instructions specific to this package are in the http://lsdtopotools.github.io/LSDTT_book/#_basinwide_cosmogenic_analysis[chapter on CRN analysis]

== Quick Guide

If you already know what you are doing, here is a quick guide to walk you through the process.
If one of these steps doesn't make sence see the full documentation.

. You will want a directory for both the source code and the data. Make these directories.
. Get the latest version of the source code from https://github.com/LSDtopotools/LSDTopoTools_CRNBasinwide
If you don't have it, use
+
[source,console]
----
$ git clone https://github.com/LSDtopotools/LSDTopoTools_CRNBasinwide.git
----
+
or if you have it use
+
[source,console]
----
$ git pull -u origin master
----
+
in your source code directory.
. If you have just downloaded the source code, or if it has updates, you need to compile the code.
Go into the folder *driver_functions_CRNBasinwide* and use make:
+
[source,console]
----
$ make -f Spawn_DEMS_for_CRN.make
$ make -f Shielding_for_CRN.make
$ make -f Basinwide_CRN.make
----
+
After each call to `make` there will be a bunch of warnings that you can ignore.
. In your data folder you will need a `*_CRNRasters.csv` file, a `*_CRNData.csv` file,
and a `*.CRNParams` file. If you don't know what these are read the relevent parts of the full documentation
. In your data folder you will also need some python scripts, which you can download individually:
+
[source,console]
----
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/JoinSnowShielding.py
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/LSDOSystemTools.py
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/EliminateUnderscoreFromCRNDataSampleNames.py
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/PrepareDirectoriesForBasinSpawn.py
----
. In your data folder, run `PrepareDirectoriesForBasinSpawn.py`.
You will need to update the path and the prefix at the bottom of this file.
. In addition, sample names with the underscore character (`_`) are not allowed. The script
`EliminateUnderscoreFromCRNDataSampleNames.py` will replace all `_` characters with `-` characters.
You need to open this file and change the target directory before running. It will modify all `*_CRNData.csv` files it finds in that directory.
. Next up, spawn the basins. Go into the source code directory and run:
+
[source,console]
----
$ ./Spawn_DEMs_for_CRN.exe PATHNAME DATAPREFIX
----
+
. Now, you are ready to calculate topographic shielding. You should run:
+
[source,console]
----
$ ./Shielding_for_CRN.exe PATHNAME DATAPREFIX
----
+
NOTE: If you ran the spawning the data prefix will now have a `*_spawned` in it.
+
WARNING: This is the most computationally expensive component of the process. It could take a while. In the full documentation there is some instructions as to how to do this computation using an embarrassingly parallel approach.
+
. If you decide to use previously reported snow shielding values, run the `JoinSnowShielding.py` function.
This will result in data files with the text `*_SS` in it.
+
. Questions? http://lsdtopotools.github.io/LSDTT_book/[Read the documentation], 
and if you can't find the answer http://www.ed.ac.uk/schools-departments/geosciences/people?indv=1591[email Simon].


